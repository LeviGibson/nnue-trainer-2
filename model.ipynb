{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from Loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "x_train = None\n",
    "x_val = None\n",
    "x_train = DataLoader(BATCH_SIZE, 'training_generator')\n",
    "x_val = DataLoader(BATCH_SIZE, 'training_generator', filename=\"val_chessData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossHistory = []\n",
    "valHistory = []\n",
    "\n",
    "class NnueCallbacks(tf.keras.callbacks.Callback):\n",
    "  def on_batch_end(self, batch, logs=None):\n",
    "    lossHistory[-1].append(logs['loss'])\n",
    "    if batch and batch % 15000 == 0:\n",
    "\n",
    "      pred = self.model.predict(x_val)\n",
    "      loss = (pred.flatten() - x_val.labels.flatten()[0:len(x_val)*BATCH_SIZE]) ** 2\n",
    "      loss = np.sum(loss) / len(loss)\n",
    "      valHistory[-1].append(loss)\n",
    "\n",
    "      for i in lossHistory:\n",
    "        plt.plot(i[20:], linewidth=0.5)\n",
    "        plt.savefig(\"loss.png\", dpi=400)\n",
    "      plt.clf()\n",
    "\n",
    "      for i in valHistory:\n",
    "        plt.plot(i, linewidth=0.5)\n",
    "        plt.savefig(\"val.png\", dpi=400)\n",
    "      \n",
    "      plt.clf()\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def clipped_relu(x):\n",
    "    return K.relu(x, max_value=4)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(781,), activation=clipped_relu))\n",
    "model.add(Dense(32, activation=clipped_relu))\n",
    "model.add(Dense(32, activation=clipped_relu))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"production/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "123006/123006 [==============================] - 2181s 18ms/step - loss: 0.0124 - mae: 0.0587 - val_loss: 0.0164 - val_mae: 0.0690\n",
      "Epoch 2/100\n",
      "123006/123006 [==============================] - 2215s 18ms/step - loss: 0.0105 - mae: 0.0527 - val_loss: 0.0168 - val_mae: 0.0688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7face8550fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossHistory.append([])\n",
    "valHistory.append([])\n",
    "model.fit(x_train, validation_data=x_val, epochs=100, callbacks=[NnueCallbacks(), EarlyStopping(patience=1)])\n",
    "\n",
    "#Epoch 2/2\n",
    "#10906/10906 [==============================] - 225s 21ms/step - loss: 0.0243 - mae: 0.0866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15982483]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Features\n",
    "import numpy as np\n",
    "\n",
    "FEN = \"r3n1k1/2qbbppp/4p3/3p2P1/2p2P2/2N1P3/Pr1B2BP/R2Q1RK1 b - - 2 19\"\n",
    "features = Features.get(FEN)\n",
    "model.predict(np.array([features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 11:02:52.337959: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: production/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"production\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
