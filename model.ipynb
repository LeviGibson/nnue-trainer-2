{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from Loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "#38.3 s\n",
    "#8:55 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "# x_train = None\n",
    "# x_val = None\n",
    "x_train = DataLoader(BATCH_SIZE, 'training_generator')\n",
    "x_val = DataLoader(BATCH_SIZE, 'training_generator', val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossHistory = []\n",
    "valHistory = []\n",
    "\n",
    "class NnueCallbacks(tf.keras.callbacks.Callback):\n",
    "  def on_batch_end(self, batch, logs=None):\n",
    "    return\n",
    "    lossHistory[-1].append(logs['loss'])\n",
    "    if batch and batch % 15000 == 0:\n",
    "\n",
    "      pred = self.model.predict(x_val)\n",
    "      loss = (pred.flatten() - x_val.labels.flatten()[0:len(x_val)*BATCH_SIZE]) ** 2\n",
    "      loss = np.sum(loss) / len(loss)\n",
    "      valHistory[-1].append(loss)\n",
    "\n",
    "      for i in lossHistory:\n",
    "        plt.plot(i[20:], linewidth=0.5)\n",
    "        plt.savefig(\"loss.png\", dpi=400)\n",
    "      plt.clf()\n",
    "\n",
    "      for i in valHistory:\n",
    "        plt.plot(i, linewidth=0.5)\n",
    "        plt.savefig(\"val.png\", dpi=400)\n",
    "      \n",
    "      plt.clf()\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def clipped_relu(x):\n",
    "    return K.relu(x, max_value=4)\n",
    "\n",
    "input = Input(shape=(769,))\n",
    "layers = Dense(128, activation=clipped_relu)(input)\n",
    "layers = Dense(32, activation=clipped_relu)(layers)\n",
    "layers = Dense(32, activation=clipped_relu)(layers)\n",
    "layers = Concatenate()([layers, input])\n",
    "layers = Dense(1, activation='sigmoid')(layers)\n",
    "\n",
    "model = Model(inputs=[input], outputs=[layers])\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(128, input_shape=(769,), activation=clipped_relu))\n",
    "# model.add(Dense(32, activation=clipped_relu))\n",
    "# model.add(Dense(32, activation=clipped_relu))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"production/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7812/7812 [==============================] - 41s 5ms/step - loss: 0.0179 - mae: 0.0884 - val_loss: 0.0245 - val_mae: 0.1008\n",
      "Epoch 2/100\n",
      "7812/7812 [==============================] - 39s 5ms/step - loss: 0.0124 - mae: 0.0726 - val_loss: 0.0239 - val_mae: 0.0960\n",
      "Epoch 3/100\n",
      "7812/7812 [==============================] - 40s 5ms/step - loss: 0.0109 - mae: 0.0678 - val_loss: 0.0232 - val_mae: 0.0966\n",
      "Epoch 4/100\n",
      "7812/7812 [==============================] - 40s 5ms/step - loss: 0.0099 - mae: 0.0647 - val_loss: 0.0230 - val_mae: 0.0937\n",
      "Epoch 5/100\n",
      "7812/7812 [==============================] - 40s 5ms/step - loss: 0.0093 - mae: 0.0627 - val_loss: 0.0228 - val_mae: 0.0924\n",
      "Epoch 6/100\n",
      "7812/7812 [==============================] - 39s 5ms/step - loss: 0.0088 - mae: 0.0610 - val_loss: 0.0227 - val_mae: 0.0913\n",
      "Epoch 7/100\n",
      "7812/7812 [==============================] - 41s 5ms/step - loss: 0.0085 - mae: 0.0599 - val_loss: 0.0226 - val_mae: 0.0907\n",
      "Epoch 8/100\n",
      "7812/7812 [==============================] - 41s 5ms/step - loss: 0.0081 - mae: 0.0588 - val_loss: 0.0229 - val_mae: 0.0909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc765767eb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossHistory.append([])\n",
    "valHistory.append([])\n",
    "model.fit(x_train, validation_data=x_val, epochs=100, callbacks=[NnueCallbacks(), EarlyStopping(patience=1)])\n",
    "\n",
    "# Epoch 1/100\n",
    "# 7812/7812 [==============================] - 41s 5ms/step - loss: 0.0180 - mae: 0.0885 - val_loss: 0.0247 - val_mae: 0.1000\n",
    "# Epoch 2/100\n",
    "# 7812/7812 [==============================] - 38s 5ms/step - loss: 0.0124 - mae: 0.0724 - val_loss: 0.0245 - val_mae: 0.0994\n",
    "# Epoch 3/100\n",
    "# 7812/7812 [==============================] - 39s 5ms/step - loss: 0.0109 - mae: 0.0677 - val_loss: 0.0236 - val_mae: 0.0945\n",
    "# Epoch 4/100\n",
    "# 7812/7812 [==============================] - 39s 5ms/step - loss: 0.0099 - mae: 0.0646 - val_loss: 0.0230 - val_mae: 0.0929\n",
    "# Epoch 5/100\n",
    "# 7812/7812 [==============================] - 38s 5ms/step - loss: 0.0092 - mae: 0.0623 - val_loss: 0.0237 - val_mae: 0.0957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15982483]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Features\n",
    "import numpy as np\n",
    "\n",
    "FEN = \"r3n1k1/2qbbppp/4p3/3p2P1/2p2P2/2N1P3/Pr1B2BP/R2Q1RK1 b - - 2 19\"\n",
    "features = Features.get(FEN)\n",
    "model.predict(np.array([features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 09:32:21.659838: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: production/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"production\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
