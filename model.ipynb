{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from Loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "#38.3 s\n",
    "#8:55 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "# x_train = None\n",
    "# x_val = None\n",
    "x_train = DataLoader(BATCH_SIZE, 'training_generator')\n",
    "x_val = DataLoader(BATCH_SIZE, 'training_generator', val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossHistory = []\n",
    "valHistory = []\n",
    "\n",
    "class NnueCallbacks(tf.keras.callbacks.Callback):\n",
    "  def on_batch_end(self, batch, logs=None):\n",
    "    return\n",
    "    lossHistory[-1].append(logs['loss'])\n",
    "    if batch and batch % 15000 == 0:\n",
    "\n",
    "      pred = self.model.predict(x_val)\n",
    "      loss = (pred.flatten() - x_val.labels.flatten()[0:len(x_val)*BATCH_SIZE]) ** 2\n",
    "      loss = np.sum(loss) / len(loss)\n",
    "      valHistory[-1].append(loss)\n",
    "\n",
    "      for i in lossHistory:\n",
    "        plt.plot(i[20:], linewidth=0.5)\n",
    "        plt.savefig(\"loss.png\", dpi=400)\n",
    "      plt.clf()\n",
    "\n",
    "      for i in valHistory:\n",
    "        plt.plot(i, linewidth=0.5)\n",
    "        plt.savefig(\"val.png\", dpi=400)\n",
    "      \n",
    "      plt.clf()\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def clipped_relu(x):\n",
    "    return K.relu(x, max_value=4)\n",
    "\n",
    "input1 = Input(shape=(768,), sparse=True)\n",
    "input2 = Input(shape=(768,), sparse=True)\n",
    "accumulator = Dense(128, activation=clipped_relu)\n",
    "\n",
    "layers = concatenate([accumulator(input1), accumulator(input2)])\n",
    "layers = Dense(32, activation=clipped_relu)(layers)\n",
    "layers = Dense(32, activation=clipped_relu)(layers)\n",
    "layers = Dense(1, activation='sigmoid')(layers)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=[layers])\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(128, input_shape=(769,), activation=clipped_relu))\n",
    "# model.add(Dense(32, activation=clipped_relu))\n",
    "# model.add(Dense(32, activation=clipped_relu))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"production/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "959458/959458 [==============================] - 1881s 2ms/step - loss: 0.0164 - mae: 0.0788 - val_loss: 0.0150 - val_mae: 0.0742\n",
      "Epoch 2/100\n",
      "959458/959458 [==============================] - 1870s 2ms/step - loss: 0.0156 - mae: 0.0761 - val_loss: 0.0147 - val_mae: 0.0735\n",
      "Epoch 3/100\n",
      "959458/959458 [==============================] - 1920s 2ms/step - loss: 0.0154 - mae: 0.0756 - val_loss: 0.0146 - val_mae: 0.0735\n",
      "Epoch 4/100\n",
      "959458/959458 [==============================] - 1911s 2ms/step - loss: 0.0154 - mae: 0.0754 - val_loss: 0.0146 - val_mae: 0.0730\n",
      "Epoch 5/100\n",
      "959458/959458 [==============================] - 1900s 2ms/step - loss: 0.0154 - mae: 0.0753 - val_loss: 0.0145 - val_mae: 0.0731\n",
      "Epoch 6/100\n",
      "959458/959458 [==============================] - 1892s 2ms/step - loss: 0.0153 - mae: 0.0752 - val_loss: 0.0146 - val_mae: 0.0729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16a0715520>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossHistory.append([])\n",
    "valHistory.append([])\n",
    "model.fit(x_train, validation_data=x_val, epochs=100, callbacks=[NnueCallbacks(), EarlyStopping(patience=1)])\n",
    "\n",
    "# Epoch 1/100\n",
    "# 959458/959458 [==============================] - 1610s 2ms/step - loss: 0.0170 - mae: 0.0809 - val_loss: 0.0155 - val_mae: 0.0768\n",
    "# Epoch 2/100\n",
    "# 959458/959458 [==============================] - 1603s 2ms/step - loss: 0.0161 - mae: 0.0779 - val_loss: 0.0152 - val_mae: 0.0747\n",
    "# Epoch 3/100\n",
    "# 959458/959458 [==============================] - 1601s 2ms/step - loss: 0.0159 - mae: 0.0773 - val_loss: 0.0150 - val_mae: 0.0750\n",
    "# Epoch 4/100\n",
    "# 959458/959458 [==============================] - 1597s 2ms/step - loss: 0.0158 - mae: 0.0770 - val_loss: 0.0150 - val_mae: 0.0746\n",
    "# Epoch 5/100\n",
    "# 959458/959458 [==============================] - 1601s 2ms/step - loss: 0.0158 - mae: 0.0768 - val_loss: 0.0150 - val_mae: 0.0744\n",
    "# Epoch 6/100\n",
    "# 959458/959458 [==============================] - 1600s 2ms/step - loss: 0.0157 - mae: 0.0767 - val_loss: 0.0149 - val_mae: 0.0744\n",
    "# Epoch 7/100\n",
    "# 959458/959458 [==============================] - 1607s 2ms/step - loss: 0.0157 - mae: 0.0767 - val_loss: 0.0150 - val_mae: 0.0751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15982483]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Features\n",
    "import numpy as np\n",
    "\n",
    "FEN = \"r3n1k1/2qbbppp/4p3/3p2P1/2p2P2/2N1P3/Pr1B2BP/R2Q1RK1 b - - 2 19\"\n",
    "features = Features.get(FEN)\n",
    "model.predict(np.array([features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: production/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: production/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"production\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
